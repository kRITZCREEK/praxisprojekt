#+BEGIN_SRC emacs-lisp :results silent :exports none
    (unless (find "kc-report" org-latex-classes :key 'car
                  :test 'equal))

  (add-to-list 'org-latex-classes
               '("kc-report"
                 "\\documentclass[11pt,a4paper]{scrreprt}
  \\usepackage[T1]{fontenc}
  \\usepackage{fontspec}
  \\usepackage{graphicx}
  \\defaultfontfeatures{Mapping=tex-text}
  \\setromanfont{Charis SIL}
  \\setsansfont{Gentium Plus}
  \\setmonofont[Scale=0.8]{DejaVu Sans Mono}
  \\usepackage{geometry}
        [NO-DEFAULT-PACKAGES]
        [NO-PACKAGES]"
                 ("\\chapter{%s}" . "\\chapter*{%s}")
                 ("\\section{%s}" . "\\section*{%s}")
                 ("\\subsection{%s}" . "\\subsection*{%s}")
                 ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
                 ("\\paragraph{%s}" . "\\paragraph*{%s}")
                 ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))

    (setq org-latex-pdf-process
    '("latexmk -xelatex -shell-escape -interaction=nonstopmode -pdf %f"))
    (setq org-latex-listings 'minted)
#+END_SRC

#+AUTHOR: Christoph Hegemann
# #+TITLE: Messaging -- Entkopplung von Microservices
#+TITLE: Docker als Virtualisierungstrategie
#+LATEX_CLASS: kc-report
# #+LATEX_CLASS_OPTIONS: [a4paper, oneside, abstract=true, BCOR=11pt, fontsize=11pt, draft=true, titlepage=false, headsepline=true]
#+LATEX_CLASS_OPTIONS: [a4paper, oneside, abstract=true, BCOR=11pt, fontsize=11pt, draft=false, titlepage=true, headsepline=true]
#+LATEX_HEADER: \usepackage[hyperref,x11names]{xcolor}
#+LATEX_HEADER: \usepackage[colorlinks=true,urlcolor=SteelBlue4,linkcolor=Firebrick4]{hyperref}
#+LATEX_HEADER: \usepackage[normalem]{ulem}
#+LATEX_HEADER: \usepackage[ngerman]{babel}
#+LATEX_HEADER: \usepackage{csquotes}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usemintedstyle{emacs}
#+LATEX_HEADER: \setcounter{tocdepth}{1}
#+LATEX_HEADER: \setcounter{secnumdepth}{1}
#+LATEX_HEADER: \pagestyle{headings}
#+LATEX_HEADER: \usepackage[backend=biber, style=science, backref=true]{biblatex}

#+LATEX_HEADER: \titlehead{\center{Technische Hochschule Köln}}
#+LATEX_HEADER: \subject{Praxisprojekt}
#+LATEX_HEADER: \subtitle{Für die Implementierung und Integration von Microservices}
#+LATEX_HEADER: \publishers{Betreut von Prof.\ Dr.\ Christian Kohls}
#+LATEX_HEADER: \addbibresource{literatur.bib}

#+BIBLIOGRAPHY: literatur.bib
#+LANGUAGE: de
#+OPTIONS: H:4 ':t

#+BEGIN_abstract
  Das wichtigste Prinzip in der Entwicklung einer Microservice Architektur ist,
  dass zwischen den einzelnen Services so wenige Abhängigkeiten wie nur möglich
  bestehen.
  Eine weiteres grundlegendes Prinzip ist "Don't share the database". Jeder
  Service muss also die Daten, die er benötigt um zu funktionieren, selbst
  speichern.
  Natürlich arbeiten die verschiedenen Services jedoch häufig auf den selben
  Entitäten, sodass hier eine Synchronisation stattfinden muss.
  Wie können nun also mehrere Services mit den selben Entitäten arbeiten?
#+END_abstract

* Motivation
** Microservice Architektur
*** Domain Driven Design 
    Eric Evans \cite{Evans-DomainDrivenDesign}
*** Conways Law - Melvin Conway
    organizations which design systems ... are constrained to produce designs
    which are copies of the communication structures of these organizations
*** Microservice Definition
    "Microservices are small, autonomous services that work together" \cite{Newman-BuildingMicroservices}

** Integrationsstrategien
*** Integration über eine gemeinsame (relationale) Datenbank
    #+BEGIN_QUOTE

    "If a family of integrated applications all rely on
    the same database, then you can be pretty sure that they are always
    consistent all of the time" \cite{Hohpe-EnterpriseIntegrationPatterns}

    #+END_QUOTE

    Klassischerweise integriert man verschiedene Applikationen und Services
    mithilfe einer geteilten relationen Datenbank. Diese Herangehensweise hat
    viele Vorteile:

    - Hohe Konsistenzgarantien

      Als einzige Quelle der Wahrheit, kann eine Datenbank mithilfe von
      Transaktionen dafür sorgen, dass niemals ein inkonsistenter Datenbestand
      abgespeichert werden kann.

    - Breite Unterstützung von SQL

      Es gibt für nahezu alle Sprachen und Frameworks hochwertige SQL
      Bibliotheken die sich seit vielen Jahren in der Industrie bewährt haben.

    - Ein gemeinsames Datenmodell

      Da alle Dienste mit dem selben Schema arbeiten, können schon früh
      Inkompatibilitäten zwischen den Services und Missverständnisse bei der
      Modellierung des Datenmodelles gefunden und geklärt werden.

    In einer Microservice Architektur wird die geteilte Datenbank jedoch von
    Nachteilen und Problemen geplagt. 

    - Ein gemeinsames Datenmodell

      Alle Services müssen mit demselben Datenmodell arbeiten. Dies widerspricht
      ganz deutlich dem Prinzip der "Bounded Contexts" aus Domain Driven Design.
      Nicht jeder Service hat dieselbe Sicht auf eine Entität. Hier einen
      gemeinsamen Nenner zu finden, erfordert dass sich alle Teams einigen und
      jede Änderung am Datenmodell ist ein potentieller Breaking Change für
      jeden Service.

    - Implementierungsdetails liegen offen

      Ein Schema in einer Datenbank ist als eine API zu sehen, da jeder Client
      der Datenbank auf das Schema zugreifen kann. "The DB is effectively a very
      large, shared API that is also quite brittle."
      \cite{Newman-BuildingMicroservices})

      Ein Service legt also mit seinem Datenmodell einen großen Teil seiner
      Implementierung offen. Dies sorgt für Kopplung zwischen den Services und
      widerspricht damit eindeutig der Zielsetzung der Microservice Architektur.

    - Single Point of Failure

      In einer Architektur, die darauf ausgelegt ist, einzelne Services
      unabhängig voneinander zu machen um Ausfälle lokal zu halten und
      Fehlertolerant zu sein hat eine von allen Services verwendete Datenbank
      keinen Platz. Wenn diese ausfällt ist das gesamte System ausgefallen.

    - Performanz Probleme

      Da Konsistenzgarantien nur durch Locking und Transaktionen gewährleistet
      werden können, kann ein einziger Service der viel Last auf der Datenbank
      erzeugt, alle anderen Services mit "ausbremsen".
*** Messaging
** Message Broker
*** Apache Kafka
  A high-throughput distributed messaging system

  - Partitionierter Commit Log
  - Verteilt. Also mehrere Instanzen
  - CAP Theorem
    - Consistency
    - Availability
    - +Partition Tolerance+
*** RabbitMQ/ActiveMQ


* Der Prototyp
  - Annäherung an ein realistisches Szenario
  - Services haben unterschiedliche Modelle für die selbe Entität (Domain Model)
  - Topics mit Ownern (Producern) und Consumern
  - Kommunikation zwischen Services über Kafka Message Broker
  - Der Prototyp braucht eine Story für Dinge wie Deployment oder Monitoring
  
** Produktservice
   Der Produktservice ist Owner des Produkt Topics. Er stellt eine API zur
   Verfügung, die es erlaubt Produktdaten zu ändern. In unserem Protoyp werden
   diese Änderungen zufällig generiert.

*** Modell
    Der Produktservice hat folgende Sicht auf die Produktentität:

    #+BEGIN_SRC haskell
      data Produkt = Produkt
        { id           :: String
        , name         :: String
        , beschreibung :: String
        , preis        :: Preis
        , rabatt       :: Prozent
        }
    #+END_SRC
    #+CAPTION: Produkt Modell des Produktservices
    Updates, die der Produktservice an Kafka schickt, enthalten eine Payload in
    dieser Form.

** Warenkorbservice

   Der Warenkorbservice ist Owner für kein Topic. Stattdessen verwaltet er die
   Warenkörbe der Kunden, die für die restlichen Services nicht zur Verfügung
   stehen.

   [[fig:infra-schaubild][Infra Schaubild]]

*** Modell
    Der Warenkorbservice hat folgende Sicht auf die Produktentität:
    #+BEGIN_SRC haskell
      data Produkt =
        Produkt
        { id    :: String
        , name  :: String
        , preis :: Preis
        }
    #+END_SRC
    #+CAPTION: Produkt Modell des Warenkorbservices
    Hierbei fällt auf, dass der Warenkorb nur an einem Subset der Felder der
    Produktservice Produktentität Kafka interessiert ist. Weiterhin beschreibt
    das ~preis~ Attribut den Preis, auf den der Rabatt bereits angewendet wurde.

    Es wird also eine /Selektion/ auf die vorhandenen Felder angewendet, und die
    verbleibenden Felder werden weiter durch /Transformation/ & /Aggregation/ in
    ein Modell, das der Domäne des Warenkorbes[fn:artikel] entspricht,
    transformiert.

[fn:artikel]
In Wirklichkeit ist der Begriff des *Preises* im E-Commerce noch
deutlich komplexer. Einem *Produkt* ist zunächst einmal gar kein Preis
zugewiesen. Stattdessen ist ein Produkt eine Einheit, die für die
Präsentation verwendet wird (zB. Kaffetasse). \\
Einen Preis hingegen weist man einem *Artikel* zu, der Elemente wie Art (zB.
Farbe), Region (Produkte haben in unterschiedlichen Regionen unterschiedliche
Preise) und Rabattaktionen beinhaltet.

*** API
    Der Warenkorbservice bietet die folgenden Operationen für das Bearbeiten von
    Warenkörben an.
     

**** Warenkorb anlegen
     Legt einen neuen Warenkorb an und gibt die ~id~ des Warenkorbes zurück

**** Artikel hinzufügen
     Fügt einem bestehenden Warenkorb einen Artikel in der angegebenen Quantität
     hinzu.
**** Bestellung erstellen
     Weist den Warenkorbservice an, eine Bestellung aus einem bestehenden
     Warenkorb zu erstellen und an einen eventuellen Checkoutservice
     weiterzureichen.


* Infrastruktur und Provisionierung
** Anforderungen
*** Elastizität
    Ein Message Broker wie Kafka kann zu verschiedenen Zeiten unter variierender
    Last arbeiten haben. Zu Stoßzeiten werden sehr viele Services Messages
    produzieren und abrufen. Um diesen sich ändernden Anforderungen gerecht zu
    werden, muss Kafka so aufgesetzt werden, dass dynamisch neue Broker
    hinzugefügt oder heruntergefahren werden können.
*** Automatisierung
    Die Provisionierung einer Maschine mit einem Kafka Broker muss vollständig
    automatisch ablaufen. Dies steht in direktem Bezug zu /Elastizität/ und dem
    Prinzip der Automatisierung von Microservices.
*** Resilienz
    Die Message Queue stellt einen /Single Point of Failure/ dar. Sollte sie
    ausfallen können die Services nicht miteinander kommunizieren und die
    Verfügbarkeit des Gesamtsystems kann nicht sichergestellt werden. Daher
    müssen Fallback Instanzen provisioniert werden, die einspringen wenn
    Ausfälle auftreten. Weiterhin müssen ausgefallene Instanzen automatisch
    neugestartet und provisioniert werden.

** Docker/Container Technologie
*** Warum Docker?
    "Docker aims to reduce the cycle time between code being written and code being
    tested, deployed, and used. It aims to make your applications portable, easy to
    build, and easy to collaborate on."\cite{Turnbull-TheDockerBook}

    "Docker is being used in production by multiple companies. It provides many
    of the benefits of lightweight containers in terms of efficiency and speed
    of provisioning, together with the tools to avoid many of the
    downsides."\cite{Newman-BuildingMicroservices}
*** Terminologie und Bausteine von Docker
   - Docker Daemon

     Ein Hintergrundprozess, der die laufenden Docker Container verwaltet und
     auf Kommandos des Nutzer reagiert. Dieser Daemon kann auf der gleichen
     Maschine wie der Nutzer ausgeführt werden, oder remote auf einem Server.

   - Docker Client

     Ein Docker Client ist ein Programm mit dessen Hilfe der Nutzer Befehle an
     einen Docker Daemon senden kann. Üblicherweise verwendet man einen CLI 
     (Command Line Interface) Client, es gibt aber auch bereits Clients mit
     einer graphischen Nutzeroberfläche (Kitematic).

   - Docker Images

     Ein Image ist der kleinste Building Block in der Docker Welt. Images werden
     aufeinander aufgesetzt und lassen sich in verschiedenen Projekten und
     Applikationen wiederverwenden. Ein Image beinhaltet dabei immer einen
     Befehl, wie zum Beispiel:
     1. Füge eine Datei hinzu
     2. Öffne einen Port
     3. Lade ein Source Archiv herunter
     4. Führe einen Shell Befehl aus
     5. ...

   - Docker Registry

     Eine Docker Registry ist ein Registry, bei der Nutzer ihre Images
     hochladen, versionieren und für andere Nutzer verfügbar machen können. Eine
     Docker Registry ist vergleichbar mit einem Git Server auf dem Entwickler
     ihren Source Code hochladen, versionieren und für andere Nutzer verfügbar
     machen können.

     Die Macher von Docker betreiben eine öffentliche Registry mit dem Namen
     Dockerhub. Dockerhub ist für Nutzer, die ihre Images öffentlich machen
     kostenlos, und für Unternehmen oder Nutzer die ihre Images privat verwalten
     wollen für Geld nutzbar.

     Weiterhin gibt es die Möglichkeit eine Registry selbst zu betreiben, wie es
     bei der REWE Digital der Fall ist. Hierfür sprechen einige Gründe:
     1. Mehr Kontrolle
     2. Keine Abhängigkeit von (Docker Macher)
     3. Images sind häufig mehrere 100MB groß und es ist daher schneller wenn
        die Registry nah bzw. im selben Datencenter wie die Container betrieben
        werden.

   - Docker Container

*** Infrastruktur versionierbar machen
**** Dockerfiles
    In Docker verwendet man sogenannte Dockerfiles um das Erzeugen von
    Images in reproduzierbaren Schritten festzuhalten. Dieses Dockerfile liegt
    in Textform vor, und lässt sich damit in ein Version Control System wie GIT
    einchecken und versionieren.

**** Tags
    Einzelne Images können, analog zu Git, mit Tags versehen werden, sodass
    getaggte Versionen eines Dockerimages leicht referenziert und als Bausteine
    für weitere Images verwendet werden können.
*** docker-compose koordiniert zusammengehörige Container (Bsp. n-Services + 1 Datenbank)
*** Nachteile:
   - Benötigt im großen Stil Service Discovery
   - Verleitet dazu Security Updates nicht einzuspielen
** Infrastruktur Landschaft

   #+CAPTION: Außensicht Systemlandschaft
   #+LABEL: fig:infra-schaubild
   [[./bilder/infra-schaubild.jpg]]

** Container für Services
*** librdkafka
*** Die verwendeten Images
   - Build image für Haskell Projekte 

     Base Image: fpco/stack-build

     Beinhaltet Haskell Compiler und build tools + librdkafka dependency kritzcreeek/stack-kafka-build
   - Run image für Haskell Projekte
     Base Image fpco/stack-run
     
     Beinhaltet Laufzeitabhängigkeiten für Haskell Projekte. Das sind zum
     Beispiel Systembibliotheken die dynamisch gegen die Executable gelinkt
     sind.
       + buildtools (gcc etc.)
       + eventuell weitere Abhängigkeiten (openssl)
       + librdkafka dependency kritzcreeek/stack-kafka-run
         
   - Docker Konfiguration für Services geschieht in ~stack.yaml~
     - Gebaut werden die Projekte innerhalb des Build Containers
       (kritzcreeek/stack-kafka-build). Kommando: ~stack build~
     - Run Container für die Services werden auf das Run Image aufgesetzt.
       Kommando: ~stack image container~
     - Services können mittels ~docker run -d kritzcreeek/produktservice
       produktservice~ gestartet werden.
     - Services können nun mit in docker-compose aufgenommen und leichter
       konfiguriert werden.
** Monitoring?


* Fazit
\printbibliography
