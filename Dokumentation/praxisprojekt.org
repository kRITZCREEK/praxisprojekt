#+BEGIN_SRC emacs-lisp :results silent :exports none
    (unless (find "kc-report" org-latex-classes :key 'car
                  :test 'equal))

  (add-to-list 'org-latex-classes
               '("kc-report"
                 "\\documentclass[11pt,a4paper]{scrreprt}
  \\usepackage[T1]{fontenc}
  \\usepackage{fontspec}
  \\usepackage{graphicx}
  \\defaultfontfeatures{Mapping=tex-text}
  \\setromanfont{Charis SIL}
  \\setsansfont{Gentium Plus}
  \\setmonofont[Scale=0.8]{DejaVu Sans Mono}
  \\usepackage{geometry}
        [NO-DEFAULT-PACKAGES]
        [NO-PACKAGES]"
                 ("\\chapter{%s}" . "\\chapter*{%s}")
                 ("\\section{%s}" . "\\section*{%s}")
                 ("\\subsection{%s}" . "\\subsection*{%s}")
                 ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
                 ("\\paragraph{%s}" . "\\paragraph*{%s}")
                 ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))

    (setq org-latex-pdf-process
      '("latexmk -xelatex -shell-escape -interaction=nonstopmode -f -pdf %f"))
    (setq org-latex-listings 'minted)
#+END_SRC

#+AUTHOR: Christoph Hegemann
#+TITLE: Isolation & Virtualisierung von Services mit Docker
#+LATEX_CLASS: kc-report
# #+LATEX_CLASS_OPTIONS: [a4paper, oneside, abstract=true, BCOR=11pt, fontsize=11pt, draft=true, titlepage=false, headsepline=true]
#+LATEX_CLASS_OPTIONS: [a4paper, oneside, abstract=true, BCOR=11pt, fontsize=11pt, draft=false, titlepage=true, headsepline=true]
#+LATEX_HEADER: \usepackage[hyperref,x11names]{xcolor}
#+LATEX_HEADER: \usepackage[colorlinks=true,urlcolor=SteelBlue4,linkcolor=Firebrick4]{hyperref}
#+LATEX_HEADER: \usepackage[normalem]{ulem}
#+LATEX_HEADER: \usepackage[ngerman]{babel}
#+LATEX_HEADER: \usepackage{csquotes}
#+LATEX_HEADER: \usepackage{epigraph}
#+LATEX_HEADER: \setlength{\epigraphwidth}{0.8\textwidth}
#+LATEX_HEADER: \usepackage[cache=false]{minted}
#+LATEX_HEADER: \usemintedstyle{emacs}
#+LATEX_HEADER: \setcounter{tocdepth}{1}
#+LATEX_HEADER: \setcounter{secnumdepth}{1}
#+LATEX_HEADER: \pagestyle{headings}
#+LATEX_HEADER: \usepackage[backend=biber, style=science, backref=true]{biblatex}

#+LATEX_HEADER: \titlehead{\center{Technische Hochschule Köln}}
#+LATEX_HEADER: \subject{Praxisprojekt}
#+LATEX_HEADER: \subtitle{Im Kontext der Implementierung und Integration von Microservices}
#+LATEX_HEADER: \publishers{Betreut von Prof.\ Dr.\ Christian Kohls}
#+LATEX_HEADER: \addbibresource{literatur.bib}

#+BIBLIOGRAPHY: literatur.bib
#+LANGUAGE: de
#+OPTIONS: H:4 ':t

#+BEGIN_abstract
Bei der REWE digital wird ein großes Softwareprojekt umgesetzt. Um die große
Anzahl an Teams, Entwicklern und Systemen zu bändigen hat man sich für eine
Microservice Architektur entschieden. Das Aufteilen der Domäne in viele kleine,
unabhängige Bereiche erlaubt es Komplexität auf der Software Ebene gering zu
halten, bringt jedoch neue Schwierigkeiten im Bereich von Operations, Deployment
und Integration mit sich.

Ein Ansatz um die gestiegene Komplexität von Provisionierung und Integration von
Microservices anzugehen ist Virtualisierung mithilfe von Containertechnologie,
wie die derzeit verbreiteste Lösung, das von der gleichnamigen Firma entwickelte
Docker. In diesem Praxisprojekt werde ich mit der Implementierung von
Microservices und ihrem Deployment mithilfe von Docker beschäftigen und meine
Fortschritte sowie Rückschläge dokumentieren.
#+END_abstract

* Motivation

#+BEGIN_LATEX
\epigraph{Move fast and break things. Unless you are breaking stuff, you are not moving fast enough.}
{\textsc{Mark Zuckerberg}}
#+END_LATEX
** Projektumfeld
   Bei der REWE digital arbeiten mehr als 20 autonome Teams mit jeweils 5-9
   Mitarbeitern an über 100 verschiedenen Services. Es werden laufend neue
   Features implementiert und möglichst schnell an den Kunden weitergereicht.
   Das Unternehmen wächst, ähnlich wie seine Codebase, schnell und braucht ein
   agiles Entwicklungsmodell, das auf die sich rapide ändernde Entwicklerzahl
   reagieren kann. Um die Entwicklung der Services parallel und unabhängig
   voneinander zu ermöglichen verfolgt man die Strategie der Microservice
   Architektur.
** Microservice Architektur
*** Microservices - Was & Warum?
    #+BEGIN_QUOTE
    Microservices are small, autonomous services that work together

    -- Sam Newman cite:Newman-BuildingMicroservices 
    #+END_QUOTE

    Die zentrale Idee hinter Microservices ist es, große Systeme, auch gerne
    /Monolithen/ genannt, in kleinere lose gekoppelte System zu zerlegen. Viel
    wichtiger als die "Definition" von Microservices sind jedoch die Vorteile
    und Herausforderungen die sie mit sich bringen.

    Kleine Services lassen sich schneller ändern. Sollte sich herausstellen,
    dass die falsche Herangehensweise gewählt wurde, kann ein bereits
    geschriebener Microservice in vertretbarem Zeitaufwand sogar komplett neu
    geschrieben werden. Durch die lose Kopplung der Services können Teams
    parallel arbeiten und an Services unabhängig voneinander weiterentwickeln,
    ohne sich gegenseitig zu blocken oder auszubremsen. Dies erlaubt es eine
    große Anzahl von Entwicklern in einem agilen Stil arbeiten zu lassen und
    effektive Teamgrößen (5 -- 7 Mitglieder) einzusetzen.

    Ein weiterer wichtiger Vorteil von Microservices ergibt sich aus der
    Korrelation von Organisationsstruktur und Softwarestruktur. Da ein Service
    von genau einem Team betreut wird, besagt /Conways Law/ cite:Conway-Commitees, dass innerhalb
    dieses Services eine hohe Kohäsion zu erwarten ist, während Services die von
    unterschiedlichen Teams entwickelt werden lose gekoppelt sein werden.
    #+BEGIN_QUOTE
    Organizations which design systems ... are constrained to produce designs
    which are copies of the communication structures of these organizations.

    -- Melvin E. Conway cite:Conway-Commitees 
    #+END_QUOTE

# *** Domain Driven Design
#     Eric Evans \cite{Evans-DomainDrivenDesign}
** Problemstellung Integration
   Eine der wichtigsten Herausforderungen, die eine Microservice Architektur mit
   sich bringt, ist es verschiedene Services miteinander zu integrieren. Es muss
   sichergestellt werden, dass Services Daten austauschen können, untereinander
   konsistent sind und dennoch nicht zu eng gekoppelt sind.

*** Integrationsstrategien

    Um den Datenaustausch zwischen Services zu ermöglichen, gibt es verschiedene
    Integationsstrategien. Ich werde diese hier nur anreißen, und stattdessen
    das Thema in meiner Bachelorarbeit noch einmal aufgreifen.

    1. Integration über eine gemeinsame (relationale) Datenbank

       Eine weit verbreitete Strategie ist die Integration über eine gemeinsame
       Datenbank, bei der mehrere Services dasselbe Schema in einer Datenbank
       verwenden und Daten austauschen, indem sie in die Datenbank Datensätze
       speichern. Dieser Ansatz bietet hohe Konsistenzgarantien.
       #+BEGIN_QUOTE
       If a family of integrated applications all rely on
       the same database, then you can be pretty sure that they are always
       consistent all of the time
       -- Gregor Hohpe cite:Hohpe-EnterpriseIntegrationPatterns 
       #+END_QUOTE
       Im Kontext einer Microservice Architektur hat die gemeinsame Datenbank
       jedoch auch viele Nachteile, die sich vor allem auf die Autonomität und
       lose Kopplung der Services auswirken. Aus diesen Gründen ist die
       empfohlene und bei REWE verwendetete Strategie /Messaging/.

    2. Messaging
       #+BEGIN_QUOTE
       Messaging makes applications loosely coupled by communicating asynchronously
       -- Gregor Hohpe cite:Hohpe-EnterpriseIntegrationPatterns
       #+END_QUOTE
       Bei Messaging senden sich verschiedene Systeme kleine Datenpakete über
       einen Messagebus. Dieser Messagebus, oder auch Messagebroker genannt,
       sorgt dafür das Nachrichten an die richtigen Empfänger zugestellt werden.
       
       Bei REWE digital hat man sich für das Messaging System /Apache Kafka/
       entschieden, dass sich selbst als /A high-throughput distributed
       messaging system/[fn:kafka] beschreibt.

       In diesem Praxisprojekt werde ich evaluieren wie sich Apachae Kafka für die
       Integration von Microservices eignet und ob es sich mithilfe von Docker
       deployen und in eine Umgebung einbetten lässt.

       
[fn:kafka]
[[http://kafka.apache.org/][Kafka Homepage - http://kafka.apache.org/]]

*** Umgebungen
    Eine besondere Schwierigkeit, die sich im Hinblick auf die Integration in
    einer Microservice Architektur ergibt, ist dass durch die Autonomität und
    Anzahl der Services viele bewegende Teile zusammengehalten werden müssen.
    Jeder Service muss unabhängig von anderen Services deployt werden können,
    was auch beinhaltet, dass jedes Team in der Lage sein muss seinen Service
    gegen den aktuellen Entwicklungsstand anderer Services testen zu können. Um
    diese sogenannten Integrationstests durchführen zu können, gibt es mehrere
    Umgebungen in welche Services deployt werden können.

    1. DEV
      
       Development Umgebung. Hier sollten Tests durchgeführt werden, die nur den
       betroffenen Service und eventuelle benötigte Infrastruktur (Datenbank)
       benutzen. Continuous Integration Systeme nutzen diese Umgebung um Unit
       Tests auszuführen.
    2. TEST/INT
    
       Umgebung für Integrationstests zwischen mehreren Services. Hier sollte
       der aktuellste Release Candidate eines Services deployt sein. Auf diese
       Weise soll verhindert werden, dass Services zu weit von ihrem
       Produktionsstand abweichen und erst in Produktion wieder aufeinander
       treffen.
    3. PRE
       
       Spiegelt die Produktionsumgebung möglichst genau. Die letzte Möglichkeit
       um kritische Bugs zu finden.
    4. PROD
       
       Die Produktionsumgebung. Wenn ein Service hier angekommen ist, wird er
       von Kunden genutzt und erzeugt Umsatz.

    Um Integrations- und Servicetests effizient umsetzen zu können, müssen die
    Testumgebungen der Produktionsumgebung so ähnlich wie möglich sein.

    #+BEGIN_QUOTE
    These differences in environments can introduce a few problems.

    -- Sam Newman (Building Microservices S.114) cite:Newman-BuildingMicroservices
    #+END_QUOTE

    In diesem Praxisprojekt werde ich mich mit der Virtualisierungstechnologie
    Docker beschäftigen, die es ermöglichen soll die Unterschiede zwischen
    Umgebungen klein zu halten und Microservices somit leichter entwickeln zu
    können.


* Der Prototyp
  Um die Tauglichkeit von Docker und Kafka zu untersuchen und kritische Fragen
  bereits frühzeitig aufdecken zu können, wurde sich dafür entschieden einen
  Prototyp zu entwicklen, der sich der aktuellen Systemstruktur annähert und
  eine breite Menge an bekannten Szenarien und Schwierigkeiten abdeckt.

** Aufbau
  Es sollen zwei Services implementiert werden, die per Messaging über Kafka
  integriert und vollständig unabhängig voneinander in Docker Containern
  ausgerollt werden können. Weiterhin müssen sie unabhängig skalierbar sein und
  der Ausfall des einen Services darf den anderen Service nicht beeinflussen.

  Inhaltlich sollen die Services sich mit einer gemeinsamen Entität
  beschäftigen, auf die sie jedoch unterschiedliche Sichten haben. In Kafka wird
  diese Entität als ein Topic abgebildet, welcher von einem der Services als
  "Owner" oder Producer und von dem anderen Service als Consumer konsumiert
  wird. Für den Prototypen wurde sich für einen /Produktservice/ und einen
  /Warenkorbservice/ entschieden. Beide dieser Services, natürlich in
  komplexerer Form, finden sich auch in der tatsächlichen Anwendung bei REWE
  wieder.

  Der generelle Aufbau des Prototypen wird in [[fig:architektur-schaubild]]
  dargestellt.

  #+CAPTION: Aufbau Prototyp
  #+LABEL: fig:architektur-schaubild
  [[./bilder/architektur.eps]]

** Programmiersprache -- Haskell
   Bei der Frage nach der zu verwendenden Programmiersprache wurde sich für
   /Haskell/ entschieden. Die Motivation für diese Wahl ist primär, dass ich am
   schnellsten und leichtesten in Haskell entwickeln kann. Die Sprache in der
   ein Microservice implementiert ist, ist prinzipiell ein
   Implementierungsdetail und kann von Service zu Service unterschiedlich sein.

   Haskell ist eine rein funktionale, statisch getypte Programmiersprache, die
   es dem Entwickler erlaubt einen hohen Grad an Sicherheit im Bezug auf die
   Korrektheit seines Programmes zu haben. Ein weiterer wichtiger Punkt, ist
   dass das ausdrucksstarke Typsystem umfangreiche Metaprogrammierung zur
   Kompilierzeit zulässt und ich somit in der Lage war einen großen Teil der En-
   und Dekodierungsfunktionen generieren zu lassen.

** Kommunikation & Protokoll
   Die Messages, mit denen die Services kommunizieren, werden in JSON enkodiert.
   Der JSON Standard (JavaScript Object Notation)[fn:json] ist ein weit verbreitetes,
   simples und menschenlesbares Austauschformat, welches vor allem im Bereich
   der Webentwicklung eingesetzt wird.
   
[fn:json] http://www.json.org/

*** Message Wrapper
    Die in JSON serialisierten Entitäten werden in einen Message Wrapper
    eingepackt, der für die technische Umsetzung relevante Metadaten enthält.

#+BEGIN_SRC haskell
data Message a =
  Message
  { id      :: UUID -- identifiziert die Nachricht
  , key     :: Text -- identifiziert die Entität
  , time    :: UTCTime
  , type    :: Text -- Art der Änderung ("created", "modified", "deleted")
  , payload :: a
  }
#+END_SRC
    Der /Typparameter/ ~a~ lässt sich mit Java's Generics vergleichen. Er gibt
    an welchen Typ von Entität die Nachricht beinhaltet. Im Prototypen kann dies
    Beispielsweise ein ~Message Produkt~ ergeben.

** Bounded Context

    Dass die Services eine unterschiedliche Sicht auf dieselbe Entität und damit
    auch unterschiedliche Datenmodelle haben, spiegelt eines der wichtigsten
    Konzepte des Domain Driven Design's wieder. Der /Bounded Context/ beschreibt
    fachliche Bereiche innerhalb einer Domäne, in denen ein gemeinsames
    Verständnis für bestimmte Objekte und Entitäten besteht. Als Beispiel könnte
    man hier die Produktion der Lagerung innerhalb einer Fabrik
    gegenüberstellen. Beide Bereiche beschäftigen sich mit Produkten, innerhalb
    der Produktion sind jedoch Eigenschaften wie Fertigungsdauer und
    Rohmaterialien interessant, während sich das Lager mit Eigenschaften wie
    Gewicht, Größe und Haltbarkeitdauer beschäftigt.

    #+BEGIN_QUOTE
    As you try to model a larger domain, it gets progressively harder to build a
    single unified model. Different groups of people will use subtly different
    vocabularies in different parts of a large organization. cite:Fowler-BoundedContext
    -- Martin Fowler
    #+END_QUOTE

    Um diese Situation in dem zu entwickelnded Prototypen abzubilden, müssen die
    beiden gewählten Services, /Produktservice/ und /Warenkorbservice/ ein
    unterschiedliches Datenmodell für die selbe Entität *Produkt* haben und an
    den Servicegrenzen zwischen den Repräsentationen konvertieren können.

** Produktservice
   Der Produktservice ist Owner des Produkt Topics. Er stellt eine API zur
   Verfügung, die es erlaubt Produktdaten zu ändern. Hier könnten in der
   Realität mehrere Anwendungen Produktdaten ändern. Beispiele wären eine
   Webanwendung, in der Fachmitarbeiter Änderungen durchführen, sowie ein
   regelmäßiger Dienst, der die neuesten Angebote und Rabattaktionen automatisch
   einspielt. Im Protoyp werden diese Änderungen zufällig generiert.

*** Modell
    Der Produktservice hat folgende Sicht auf die Produktentität:

    #+BEGIN_SRC haskell
      data Produkt = Produkt
        { id           :: String
        , name         :: String
        , beschreibung :: String
        , preis        :: Preis
        , rabatt       :: Prozent
        }
    #+END_SRC

*** Enkodieren
    #+CAPTION: Produkt Modell des Produktservices
    Updates, die der Produktservice an Kafka schickt, enthalten eine Payload die
    ein Produkt enthält. Eine Entität vom Typ ~Produkt~ wird hierfür in das JSON
    Format /enkodiert/, im ~Message~ Wrapper eingepackt und an Kafka
    weitergereicht.

#+BEGIN_SRC haskell
  sendRandomProduct =
    produceMessage topic (KafkaSpecifiedPartition partition)  -- (4)
    . KafkaProduceMessage -- (4)
    . BSL.toStrict -- (3)
    . encode -- (2)
    =<< produkt -- (1)
#+END_SRC
    Der Operator für Komposition in Haskell ist der Punkt. Weil Komposition in
    der Mathematik "rückwärts" funktioniert, lässt sich der Code leichter
    rückwärts erklären.

    (1) Die ~produkt~ Methode ist im Prototypen als ein Generator definiert, der
    ~QuickCheck~ verwendet um zufällige Messages zu generieren, die Produkte
    enthalten.
#+BEGIN_SRC haskell
produkt :: IO (Message Produkt)
produkt = QC.generate QC.arbitrary
#+END_SRC

    ~QuickCheck~ arbeitet typgetrieben, und kann anhand der Typsignatur
    inferieren, dass es einen Generator für ~Message Produkt~ verwenden muss,
    den ich an anderer Stelle definiert habe.

    (2) Nachdem eine Message mit Produkt Inhalt generiert wurde, reichen wir es an
    ~encode~ weiter und enkodieren die Message damit in JSON.

    (3) Weil Haskell's Evaluierungsstrategie Lazy ist, die Kafka Bibliothek
    jedoch mit strikt evaluierten Werten arbeitet, müssen mit ~BSL.toStrict~
    die vollständige Evaluierung des JSON Wertes erzwungen werden, bevor es an
    Kafka weitergereicht werden kann.

    (4) ~produceMessage~ ist eine Funktion aus der Kafka Client Bibliothek, die
    eine Nachricht für ein gegebenes Topic, an eine gegebene Partition schickt.

** Warenkorbservice

   Der Warenkorbservice ist Owner für kein Topic. Stattdessen verwaltet er die
   Warenkörbe der Kunden, die für die restlichen Services nicht zur Verfügung
   stehen.

*** Modell
    Der Warenkorbservice hat folgende Sicht auf die Produktentität:
    #+BEGIN_SRC haskell
      data Produkt =
        Produkt
        { id    :: String
        , name  :: String
        , preis :: Preis
        }
    #+END_SRC
    #+CAPTION: Produkt Modell des Warenkorbservices

    Es fällt auf, dass der Warenkorb nur an einem Subset der Felder der
    Produktservice Produktentität Kafka interessiert ist. Das Attribut ~preis~
    beschreibt den Preis, auf den der Rabatt bereits angewendet wurde.
    
*** Dekodieren
    Um die Produktentität des Produktservices in das Modell des
    Warenkorbservices zu konvertieren, wird eine /Selektion/ auf die vorhandenen
    Felder angewendet, und die verbleibenden Felder werden weiter durch
    /Transformation/ & /Aggregation/ in ein Modell, das der Domäne des
    Warenkorbes[fn:artikel] entspricht, transformiert.

    Das /dekodieren/ und /transformieren/ sieht im Code wie folgt aus:
    #+BEGIN_SRC haskell
    instance FromJSON Produkt where
      parseJSON = withObject "Produkt" $ \o ->
        Produkt
        <$> o .: "id"
        <*> o .: "name"
        <*> (berechnePreis <$> o .: "preis" <*> o.: "rabatt")
        where
          berechnePreis :: (Integral a) => a -> Double -> a
          berechnePreis preis rabatt = floor $ fromIntegral preis * (1 - rabatt / 100)
    #+END_SRC

    Die vielen ~<$>~ und ~<*>~ sorgen für das automatische Propagieren von
    Fehlern beim deserialisieren der JSON Felder. Mithilfe der ~berechnePreis~
    Funktion werden die ~preis~ und ~rabatt~ Felder des Produktes aus dem
    Produktservice zusammengefasst.

[fn:artikel]
In Wirklichkeit ist der Begriff des *Preises* im E-Commerce noch
deutlich komplexer. Einem *Produkt* ist zunächst einmal gar kein Preis
zugewiesen. Stattdessen ist ein Produkt eine Einheit, die für die
Präsentation verwendet wird (zB. Kaffetasse). \\
Einen Preis hingegen weist man einem *Artikel* zu, der Elemente wie Art (zB.
Farbe), Region (Produkte haben in unterschiedlichen Regionen unterschiedliche
Preise) und Rabattaktionen beinhaltet.



* Infrastruktur und Provisionierung

#+BEGIN_LATEX
\epigraph{Ownership extends to all aspects of the service, from sourcing requirements to
building, deploying, and maintaining the application. \cite{Newman-BuildingMicroservices}}
{\textsc{Sam Newman}}
#+END_LATEX

  Um den Herausforderungen bei der Umsetzung einer Microservice Architektur
  gerecht zu werden, ist es wichtig, dass die Infrastruktur die Autonomie und
  Flexibilität der Teams nicht untergräbt sondern unterstützt.

** Anforderungen an die Infrastruktur
*** Elastizität
    Einer der wesentlichen Vorteile von Microservices ist es, dass durch die
    strikte Trennung zwischen den Services möglich ist Services unabhängig
    voneinander zu skalieren und der aktuellen Last anzupassen.

    Ein Message Broker wie Kafka kann zu verschiedenen Zeiten unter variierender
    Last arbeiten haben. Zu Stoßzeiten werden sehr viele Services Messages
    produzieren und abrufen. Um diesen sich ändernden Anforderungen gerecht zu
    werden, muss Kafka so aufgesetzt werden, dass dynamisch neue Broker
    hinzugefügt oder heruntergefahren werden können.

*** Automatisierung
    Die Provisionierung und das Ausrollen von Services und dem Kafka Broker muss
    vollständig automatisiert werden. Dies ist notwendig um /Elastizität/
    überhaupt realisieren zu können. Weiterhin garantiert vollständige
    Automatisierung des Provisionierens, dass auch andere Teams den Service für
    Integrationstests hochfahren können.
*** Resilienz
    Die Message Queue stellt einen /Single Point of Failure/ dar. Sollte sie
    ausfallen können die Services nicht miteinander kommunizieren und die
    Verfügbarkeit des Gesamtsystems kann nicht sichergestellt werden. Daher
    müssen Fallback Instanzen provisioniert werden, welche einspringen wenn
    Ausfälle auftreten. Weiterhin müssen ausgefallene Instanzen automatisch
    neugestartet und gegebenenfalls provisioniert werden. Mit dem Thema der
    Resilienz werde ich mich im Zuge der Bachelorarbeit noch ausführlicher
    beschäftigen.

** Docker/Container Technologie
   Um die Anforderungen erfüllen zu können muss eine leichtgewichtige
   Virtualisierungslösung gefunden werden. Die Entscheidung fällt hierbei für
   mein Praxisprojekt auf Docker.
   #+BEGIN_QUOTE
   Docker is being used in production by multiple companies. It provides many
   of the benefits of lightweight containers in terms of efficiency and speed
   of provisioning, together with the tools to avoid many of the
   downsides. cite:Newman-BuildingMicroservices 
   
     -- Sam Newman
   #+END_QUOTE
*** Was ist Docker?

    Auf seiner Website beantwortet Docker diese Frage mit folgendem Sales Pitch:
    "Docker allows you to package an application with all of its dependencies
    into a standardized unit for software development."[fn:docker-site]

    In seinem sogenannten "Docker Book" fasst James Turnbull die Vorteile und
    Ziele von Docker zu drei wesentlichen Punkten zusammen.

    #+BEGIN_QUOTE
    Docker aims to reduce the cycle time between code being written and code being
    tested, deployed, and used. It aims to make your applications portable, easy to
    build, and easy to collaborate on. cite:Turnbull-TheDockerBook 
    -- James Turnbull
    #+END_QUOTE

    1. Docker macht es leichter Software zu deployen
    2. Docker macht es leichter Software zu portieren
    3. Docker macht es leichter gemeinsam Software zu entwickeln

[fn:docker-site] https://www.docker.com/what-docker

*** Terminologie und Bausteine von Docker
   - Docker Daemon

     Ein Hintergrundprozess, der die laufenden Docker Container verwaltet und
     auf Kommandos des Nutzer reagiert. Dieser Daemon kann auf der gleichen
     Maschine wie der Nutzer ausgeführt werden, oder remote auf einem Server.

   - Docker Client

     Ein Docker Client ist ein Programm mit dessen Hilfe der Nutzer Befehle an
     einen Docker Daemon senden kann. Üblicherweise verwendet man ein CLI
     (Command Line Interface), es gibt aber auch bereits Clients mit einer
     graphischen Nutzeroberfläche (Kitematic).

   - Docker Images

     Ein Image ist der kleinste Building Block in der Docker Welt. Images bauen
     aufeinander auf und lassen sich in verschiedenen Projekten und
     Applikationen wiederverwenden. Ein Image beinhaltet dabei immer einen
     Befehl, wie zum Beispiel:
     1. Füge eine Datei hinzu
     2. Öffne einen Port
     3. Lade ein Source Archiv herunter
     4. Führe einen Shell Befehl aus
     5. ...

   - Docker Registry

     Eine Docker Registry ist ein Registry, bei der Nutzer ihre Images
     hochladen, versionieren und für andere Nutzer verfügbar machen können. Eine
     Docker Registry ist vergleichbar mit einem Git Server, auf dem Entwickler
     ihren Source Code hochladen, versionieren und für andere Nutzer verfügbar
     machen können.

     Die Macher von Docker betreiben eine öffentliche Registry mit dem Namen
     Dockerhub. Dockerhub ist für Nutzer, die ihre Images öffentlich machen
     kostenlos, und für Unternehmen oder Nutzer die ihre Images privat verwalten
     wollen für Geld nutzbar.

     Weiterhin gibt es die Möglichkeit eine Registry selbst zu betreiben, wie es
     bei der REWE digital der Fall ist. Hierfür sprechen einige Gründe:
     1. Mehr Kontrolle
     2. Keine Abhängigkeit von (Docker Macher)
     3. Images sind häufig mehrere 100MB groß und es ist daher schneller wenn
        die Registry nah bzw. im selben Datencenter wie die Container betrieben
        werden.

   - Docker Container
     
     Ein Docker Container ist eine konkrete Instanz eines Docker Images. Wenn
     ein Docker Image auf einen Host mit einem Docker Daemon deployt wird, kann
     das Image als Container gestartet werden. Es können gleichzeitig mehrere
     Container von demselben Image erzeugen. Ein Docker Container ist dabei ein
     vollständig eigenständiges System, das über Mittel wie Ports mit anderen
     Containern und Systemen kommuniziert.

*** Infrastruktur versionierbar machen
    In Docker verwendet man sogenannte Dockerfiles um das Erzeugen von Images in
    reproduzierbaren Schritten festzuhalten. Diese Dockerfiles liegen in
    Textform vor, und lassen sich damit in ein Version Control System wie Git
    einchecken und versionieren.

    Als Beispiel soll hier einmal das, mit Kommentaren versehene, Dockerfile für
    den Runtime Container dienen:

#+ATTR_LATEX: :caption dockerfile
#+BEGIN_SRC Dockerfile
# Es wird das fpco/stack-run base image verwendet, welches alle nötigen
# Laufzeitabhängigkeiten für kompilierte Haskell binaries enthält.
FROM fpco/stack-run:lts-5

# Da die Kafka Client Bibliothek librdkafka nicht in den offiziellen
# Ubuntu repositories verfügbar ist, muss sie mit build-essential
# tools wie 'gcc' und 'make' selbst kompiliert und installiert werden.

# curl wird benötigt, um den Quellcode für die Bibliothek herunterzuladen.
RUN apt-get update && \
    apt-get install -y \
      curl build-essential

# Hier wird ein mit 'tar' komprimiertes Archiv heruntergeladen, welches
# den Quellcode für librdkafka enthält.
RUN curl -o /root/librdkafka-0.9.0.99.tar.gz -SL \
      https://github.com/edenhill/librdkafka/archive/0.9.0.99.tar.gz

# Das Archiv wird entpackt
RUN tar -xzf /root/librdkafka-0.9.0.99.tar.gz -C /root && \
    cd /root/librdkafka-0.9.0.99

# Jetzt wird librdkafka kompiliert und die entstandene Bibliothek mit 
# 'make install' nach '/usr/lib' installiert wo sie für die Binaries
# der Services vefügbar ist
RUN ./configure && \
    make && \
    make install

# Hier cachen wir das anfänglich heruntergeladene Archiv um es bei
# zukünftigen Durchläufen nicht mehr herunterladen zu müssen.
RUN cd / && \
    tar czf librdkafka-0.9.0.99.tar.gz \
    usr/local/include/librdkafka usr/local/lib/librdkafka*
#+END_SRC

   Dieses Dockerfile kann nun verwendet werden, um das Laufzeitimage neu zu
   bauen. Einzelne Images können, analog zu Git, mit Tags versehen werden,
   sodass getagte Versionen eines Dockerimages leicht referenziert und als
   Bausteine für weitere Images verwendet werden können.

   Weiterhin lassen sich mit einem Tag versehene Images in eine /Docker
   Registry/ pushen. Von dort können sie dann herunterladen und ausgeführt
   werden, ohne sie erneut bauen zu müssen.

** Haskell Services und Docker
*** Run- und Buildtimecontainer
    Im Laufe des Projektes wurden verschiedene Images verwendet. Diese lassen
    in Runtimecontainer und Buildtimecontainer aufteilen.
**** Buildtimeimage
     Um die Haskell Services zu kompilieren und bauen, wurde ein Docker Image
     aufgesetzt. Es enthält folgende Toolchain:

     - stack (Ein Haskell build tool)
     - GHC (Glorious Haskell Compiler)
     - librdkafka (Kafka Client Bibliothek, in C geschrieben)

     Als Base Image wurde ~fpco/stack-build~ verwendet. Nachdem die Kafka
     Bibliothek und ein paar Systembibliotheken hinzugefügt wurden ist das Image
     jetzt unter ~kritzcreeek/stack-kafka-build~ verfügbar.

**** Runtimeimage
     Weil der Buildtimecontainer für Haskell Projekte für einen
     Laufzeitcontainer zu groß ist, wurde ein dediziertes Runtimeimage
     aufgesetzt. Es enthält die minimal notwendigen Abhängigkeiten um Services
     mit der Kafka Client Bibliothek anzusprechen. Diese werden bei der
     Kompiierung dynamisch gelinkt und müssen daher auf dem Laufzeitsystem
     verfügbar sein. Weiterhin wurden folgende Bibliotheken installiert:

     - openssl (Ermöglicht verschlüsselte Kommunikation mit Kafka)
     - libtinfo (Haskell binaries benötigen diese Bibliothek)

     Als Base Image wurde ~fpco/stack-run~ verwendet. Nachdem die zusätzlichen
     Bibliotheken installiert und konfiguriert wurden ist das Image unter
     ~kritzcreeek/stack-kafka-run~ verfügbar.

*** Laufzeitimages
   Die Docker Container, die die fertigen Services enthalten, werden aus den in
   [[fig:docker-images]] dargestellten Images zusammengebaut.

   #+ATTR_LATEX: :width 10cm
   #+LABEL: fig:docker-images
   #+CAPTION: Docker Images
   [[./bilder/infrastruktur.eps]]

   Die Images ~ubuntu~ und ~fpco/stack-run~ sind bereits vorhanden, und können
   so wie sie sind, als Grundlage verwendet werden. Das ~stack-kafka-run~ image
   wird durch das in [[Infrastruktur versionierbar machen]] gezeigte Dockerfile
   gebaut.

*** Docker Konfiguration mittels stack
    Haskell's am weitesten verbreitete Buildtool /stack/ bringt bereits von Haus
    Docker Integration mit, und macht es einem als Entwickler sehr einfach.
    Hierbei können Einstellungen gemacht werden, mit denen das betroffene Haskell
    Projekt in einem *Build Container* gebaut und anschließend in einem viel
    kleineren *Run Container* verpackt wird.

    Die Docker Konfiguration für Services geschieht in ~stack.yaml~, einer
    Konfigurationsdatei die im Wurzelverzeichnis jedes mit ~stack~ gebauten
    Haskell Projektes zu finden ist.

    #+NAME: stack.yaml
    #+BEGIN_SRC yaml
    docker:
      enable: true
      image: "kritzcreeek/stack-kafka-build"

    image:
      container:
        name: "kritzcreeek/produktservice"
        base: "kritzcreeek/stack-kafka-run"
    #+END_SRC
    Als Beispiel werden hier die nötigen Einstellungen, um den Produktservice
    vollständig mithilfe von Docker und dem ~kritzcreeek/stack-kafka-build~
    Image zu bauen, abgebildet.

    Mit ~docker enable: true~ wird angegeben, dass Docker verwendet wird um
    dieses Projekt zu bauen. Weiterhin wird angegeben, dass das
    ~kritzcreeek/stack-kafka-build~ Image verwendet wird um das Projekt zu
    bauen. Wird nun ~stack build~ im Wurzelverzeichnis des Service Projektes
    ausgeführt, geschehen folgende, für den User nicht sichtbare, Schritte:

    1. Es wird ein neuer Docker Container auf Basis des
       ~kritzcreeek/stack-kafka-build~ Images gestartet.

    2. ~stack~ verwendet einen Symlink, um das Projektverzeichnis in dem
       Container erreichbar zu machen.

    3. Der Haskell Compiler kompiliert das Projekt innerhalb des Containers.

    4. Die fertig kompilierten Build Artefakte werden in einem ~.stack~ Ordner
       im Wurzelverzeichnis des Projektes abgelegt.

    5. Der Build Container wird wieder gestoppt.

    Der ~image~ Eintrag in der ~stack.yaml~ Datei gibt an, dass aufbauend auf
    dem ~kritzcreeek/stack-kafka-run~ Image die zuvor kompilierten Build
    Artefakte in einem Image mit dem Namem ~kritzcreeek/produktservice~ abgelegt
    werden sollen. Hierfür das ~stack image container~ Kommando ausgeführt.
    ~stack~ führt nun folgende Schritte aus:

    1. Ein neuer Docker Container wird basierend auf dem
       ~kritzcreeek/stack-kafka-run~ Image gestartet.
    2. Die sich in ~.stack~ befindlichen Buildartefakte werden in den ~/usr/bin~
       Ordner des Containers kopiert.
    3. Der neue Zustand des Containers wird als Image unter dem Namen
       ~kritzcreeek/produktservice~ abgespeichert.
    4. Der Container wird gestoppt.

    Der Produkservice kann nun mittels ~docker run -d kritzcreeek/produktservice
    produktservice~ gestartet werden. Die ~-d~ Option besagt dabei, dass der
    Container als "Daemon" gestartet werden soll, was bedeutet dass der
    Container im Hintergrund läuft und nicht die aktuelle Shell Session belegt.

** Probleme unter OSX
   Die Entwicklung des Prototypen wurde zu großen Teilen unter Apple's
   Betriebssystem OSX entwickelt. Es gibt zwei Arten Docker unter OSX zu
   betreiben. Das "normale" Vorgehen ist eine Virtual Machine mit einem Linux
   Betriebssystem zu betreiben und von OSX als Hostsystem mit dem Docker Daemon
   zu kommunizieren. Das andere Vorgehen ist das Verwenden der Docker Beta, die
   native Docker Funktionalität für OSX mitbringt. Leider musste bei der
   Entwicklung des Prototypen festgestellt werden, dass sich die Kafka Client
   Bibliothek jedoch nicht in der Docker Beta kompilieren ließ.

   Dieses Problem wurde gelöst, indem eine Virtual Machine mit Arch Linux
   verwendet wurde um die Docker Deployments zu testen.


* Fazit

In [[Motivation][Motivation (Kapitel 1)]] wurden die Ausgangslage und die Gründe für die
Entwicklung des Docker & Kafka Prototypen erläutert. In [[Microservice Architektur][Microservice Architektur
(1.1)]] wurde festgestellt, dass die Umsetzung einer Microservicearchitektur nicht
nur technische, sondern auch organisatorische Herausforderungen mit sich bringt.
Um die Autonomie von agilen Teams zu gewährleisten benötigt man eine
leichtgewichtige Virtualisierungslösung die jedes Team selbst betreiben kann. Um
die Microservices weiter zu entkoppeln, wurde sich in [[Problemstellung Integration][Problemstellung
Integration (1.2)]] für die Integrationsstrategie /Messaging/ entschieden, und
Apache Kafka als der zu verwendende Message Broker festgelegt.

In [[Der Prototyp][Der Prototyp (Kapitel 2)]] wurde das Design für den zu entwickelnden Prototypen
entwickelt. Die benötigten Komponenten wurden in [[Aufbau][Aufbau (2.1)]] aufgezeigt und
ihre Kommunikationswege definiert. Für die Entwicklung der Services wurde sich
für die [[Programmiersprache -- Haskell][Programmiersprache Haskell (2.2)]] entschieden. Wie die Services Daten
austauschen wurde in [[Kommunikation & Protokoll][Kommunikation & Protokoll (2.3)]] designed und sich für das
Austauschformat JSON entschieden. Nach einem kurzen Abstecher in das Konzept des
[[Bounded Context][Bounded Context (2.4)]], aus dem Domain Driven Design, wurde sich dann der
Implementierung des [[Produktservice][Produktservices (2.5)]] und des [[Warenkorbservice][Warenkorbservices (2.6)]]
zugewandt.

In [[Infrastruktur und Provisionierung][Infrastruktur und Provisionierung (Kapitel 3)]] wurde sich damit beschäftigt,
wie die entwickelten Services deployt und betrieben werden können. Zunächst
wurden einige [[Anforderungen an die Infrastruktur][Anforderungen an die Infrastruktur (3.1)]] ermittelt. Um diese
Anforderungen zu erfüllen wurde sich für [[Docker/Container Technologie][Docker/Container Technologie (3.2)]]
entschieden und die nötige Terminologie und Herausforderungen für den Einsatz
von Docker erläutert. Es wurde untersucht wie [[Haskell Services und Docker][Haskell Services und Docker (3.3)]]
miteinander zusammenspielen und festgestellt, dass Haskell's Buildtooling
bereits die wichtigsten Features mitbringt. Bei der Entwicklung gab es zwar
wenige [[Probleme unter OSX][Probleme unter OSX (3.4)]], diese ließen sich jedoch leicht umgehen und
zusammenfassend verlief das Arbeiten mit Docker überraschend reibungslos.

Der Prototyp war ein Erfolg. Es ist ein System aus mehreren Microservices
entstanden, das den Anforderungen des Domain Driven Design genügt, leicht
portierbar ist (dank Docker) und problemlos mit weiteren in Docker verpackten
Services erweitert werden könnte. Apache Kafka hat mit dem Prototypen seine
erste Prüfung bestanden, wird aber in der folgenden Bachelorarbeit nocheinmal
genauer unter die Lupe genommen werden.

\printbibliography
